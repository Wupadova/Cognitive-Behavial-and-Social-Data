{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wupadova/Cognitive-Behavior-and-Social-Data/blob/main/Cognitive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-iYsyiZsMC5"
      },
      "source": [
        "##Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKNnNwxxSebf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82c258f-61a7-4adf-efa9-273c23e6427c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.4-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-4.1.0-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.44)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 15.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.7.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<5.0.0->optuna) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 50.4 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 18.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=ad74b156980e878906874d3df3b6542bb22e1de3548634bc52558aa121f8f660\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-4.1.0 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.4 pbr-5.11.0 pyperclip-1.8.2 stevedore-4.1.1\n"
          ]
        }
      ],
      "source": [
        "#Generical libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import itertools\n",
        "from prettytable import PrettyTable\n",
        "from google.colab import drive\n",
        "\n",
        "#Loading, preprocessing and splitting the dataset\n",
        "from urllib.request import urlopen\n",
        "from collections import Counter\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Perceptron \n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "#Decision Tree and Random Forest\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay \n",
        "\n",
        "#Support Vector Machine (SVM)\n",
        "from sklearn import svm\n",
        "\n",
        "#Neural Network (NN)\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.python.framework.random_seed import set_random_seed\n",
        "from tensorflow.keras.models import Sequential \n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "#K-Nearest Neighbour (kNN)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#Optuna hyperparameter tuning\n",
        "!pip install optuna\n",
        "import optuna as op\n",
        "from optuna.visualization import plot_contour\n",
        "#PCA\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#SelectKBest\n",
        "#from sklearn.datasets import load_digits\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "#Metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7bWzVyZsTqb"
      },
      "source": [
        "##Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghTYqDf9USyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4271dbf1-ee2e-482f-9595-54fe372cfbd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLo381_0XRyH"
      },
      "outputs": [],
      "source": [
        "#import datasets\n",
        "df_1_DT_df_CC = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/1. shortDT (2)/DT_df_CC.csv\")\n",
        "df_1_DT_df_JI = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/1. shortDT (2)/DT_df_JI.csv\")\n",
        "df_2_PRMQ_df = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/2. PRMQ/PRMQ_df.csv\")\n",
        "df_3_PCL5_df = pd.read_excel(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/3. PCL/PCL5_df.xlsx\")\n",
        "df_4_NAQ_R_df = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/4. NAQ_R/NAQ_R_df.csv\")\n",
        "df_5_PHQ9_GAD7_df = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/5. PHQ9_GAD7/PHQ9_GAD7_df.csv\")\n",
        "df_6_PID5_df = pd.read_excel(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/6. PID5/PID5_df.xlsx\")\n",
        "df_7_sPID5_df = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/7. shortPID5 - Fake Bad/sPID-5_df.csv\")\n",
        "df_8_PRFQ_df = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/8. PRFQ/PRFQ_df.csv\")\n",
        "df_9_IESR_df = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/9. IESR/IESR_df.csv\")\n",
        "#df_10_Faked = pd.read_excel(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/10. R_NEO_PI/Faked.xlsx\")\n",
        "df_10_Honest = pd.read_excel(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/10. R_NEO_PI/Honest.xlsx\")\n",
        "df_11_RAW_DDDT = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/11. DDDT/RAW_DDDT.CSV\")\n",
        "df_12_IADQ_df = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/12. IADQ/IADQ_df.csv\")\n",
        "df_13_BF_df_CTU = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/13. BF (3)/BF_df_CTU.csv\")\n",
        "df_13_BF_df_OU = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/13. BF (3)/BF_df_OU.csv\")\n",
        "df_13_df_V = pd.read_csv(\"/content/drive/MyDrive/DataScience_Dataset 2022-2023/13. BF (3)/BF_df_V.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0YHpI0bAExB"
      },
      "outputs": [],
      "source": [
        "df_list = [df_1_DT_df_CC, df_1_DT_df_JI, df_2_PRMQ_df, df_3_PCL5_df, df_4_NAQ_R_df, df_5_PHQ9_GAD7_df,\n",
        "           df_6_PID5_df, df_7_sPID5_df, df_8_PRFQ_df, df_9_IESR_df, #df_10_Faked,\n",
        "            df_10_Honest, df_11_RAW_DDDT, df_12_IADQ_df, df_13_BF_df_CTU, df_13_BF_df_OU, df_13_df_V]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exploring our datasets"
      ],
      "metadata": {
        "id": "b19W9mK-H8lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for df in df_list:\n",
        "  print('Another dataset')\n",
        "  print('Data shape')\n",
        "  print(df.shape) #data shape\n",
        "  print('Data head')\n",
        "  print(df.head(5)) #display first 5 columns\n",
        "  print('Data types')\n",
        "  print(df.dtypes) #data types\n",
        "  print('Description of dataset')\n",
        "  print(df.describe()) # return analysis of each numerical value\n"
      ],
      "metadata": {
        "id": "ygPbYfoYICut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf51a1a0-c693-41e4-bf86-4c3d59dfd34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Another dataset\n",
            "Data shape\n",
            "(482, 28)\n",
            "Data head\n",
            "   Mach1   Mach2   Mach3   Mach4   Mach5   Mach6   Mach7   Mach8   Mach9   \\\n",
            "0       3       3       2       4       4       3       3       3       4   \n",
            "1       4       2       1       3       4       4       4       2       2   \n",
            "2       4       1       3       3       3       1       4       1       5   \n",
            "3       4       3       1       3       3       4       2       3       4   \n",
            "4       3       2       1       2       2       3       3       2       3   \n",
            "\n",
            "   Psycho1   ...  Narc1  Narc2   Narc3   Narc4   Narc5   Narc6  Narc7   \\\n",
            "0         2  ...      3       3       3       3       3      4       3   \n",
            "1         3  ...      4       1       3       3       2      2       3   \n",
            "2         1  ...      3       2       3       3       2      1       2   \n",
            "3         2  ...      4       4       1       2       4      2       2   \n",
            "4         2  ...      2       2       2       2       3      1       1   \n",
            "\n",
            "   Narc8   Narc9   CONDITION  \n",
            "0       4       2          H  \n",
            "1       4       5          H  \n",
            "2       3       3          H  \n",
            "3       3       4          H  \n",
            "4       3       4          H  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "Data types\n",
            "Mach1         int64\n",
            "Mach2         int64\n",
            "Mach3         int64\n",
            "Mach4         int64\n",
            "Mach5         int64\n",
            "Mach6         int64\n",
            "Mach7         int64\n",
            "Mach8         int64\n",
            "Mach9         int64\n",
            "Psycho1       int64\n",
            "Psycho2       int64\n",
            "Psycho3       int64\n",
            "Psycho4       int64\n",
            "Psycho5 H     int64\n",
            "Psycho6       int64\n",
            "Psycho7       int64\n",
            "Psycho8       int64\n",
            "Psycho9       int64\n",
            "Narc1         int64\n",
            "Narc2         int64\n",
            "Narc3         int64\n",
            "Narc4         int64\n",
            "Narc5         int64\n",
            "Narc6         int64\n",
            "Narc7         int64\n",
            "Narc8         int64\n",
            "Narc9         int64\n",
            "CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "           Mach1       Mach2       Mach3       Mach4       Mach5       Mach6   \\\n",
            "count  482.000000  482.000000  482.000000  482.000000  482.000000  482.000000   \n",
            "mean     3.796680    2.026971    2.097510    2.848548    2.707469    3.450207   \n",
            "std      0.865214    1.087301    1.054066    1.146217    1.195759    1.018850   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      3.000000    1.000000    1.000000    2.000000    2.000000    3.000000   \n",
            "50%      4.000000    2.000000    2.000000    3.000000    3.000000    4.000000   \n",
            "75%      4.000000    3.000000    2.750000    4.000000    4.000000    4.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "           Mach7       Mach8       Mach9     Psycho1   ...    Psycho9   \\\n",
            "count  482.000000  482.000000  482.000000  482.000000  ...  482.000000   \n",
            "mean     3.450207    2.217842    3.128631    2.392116  ...    1.786307   \n",
            "std      1.026980    1.090620    1.225190    1.186278  ...    1.052657   \n",
            "min      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
            "25%      3.000000    1.000000    2.000000    1.000000  ...    1.000000   \n",
            "50%      4.000000    2.000000    3.000000    2.000000  ...    1.000000   \n",
            "75%      4.000000    3.000000    4.000000    3.000000  ...    2.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000  ...    5.000000   \n",
            "\n",
            "            Narc1      Narc2       Narc3       Narc4       Narc5        Narc6  \\\n",
            "count  482.000000  482.000000  482.000000  482.000000  482.000000  482.000000   \n",
            "mean     2.956432    2.798755    2.273859    2.585062    2.902490    2.724066   \n",
            "std      1.011457    1.025130    0.807772    0.953179    1.096599    1.071557   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      2.000000    2.000000    2.000000    2.000000    2.000000    2.000000   \n",
            "50%      3.000000    3.000000    2.000000    3.000000    3.000000    3.000000   \n",
            "75%      4.000000    4.000000    3.000000    3.000000    4.000000    4.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "           Narc7       Narc8       Narc9   \n",
            "count  482.000000  482.000000  482.000000  \n",
            "mean     2.500000    2.771784    3.589212  \n",
            "std      1.075623    1.028590    0.980754  \n",
            "min      1.000000    1.000000    1.000000  \n",
            "25%      2.000000    2.000000    3.000000  \n",
            "50%      2.000000    3.000000    4.000000  \n",
            "75%      3.000000    4.000000    4.000000  \n",
            "max      5.000000    5.000000    5.000000  \n",
            "\n",
            "[8 rows x 27 columns]\n",
            "Another dataset\n",
            "Data shape\n",
            "(864, 1)\n",
            "Data head\n",
            "  Mach1 ;Mach2 ;Mach3 ;Mach4 ;Mach5 ;Mach6 ;Mach7 ;Mach8 ;Mach9 ;Psycho1 ;Psycho2 ;Psycho3 ;Psycho4 ;Psycho5 ;Psycho6 ;Psycho7 ;Psycho8 ;Psycho9 ;Narc1 ;Narc2 ;Narc3 ;Narc4 ;Narc5 ;Narc6 ;Narc7 ;Narc8 ;Narc9 ;CONDITION\n",
            "0  3;1;1;4;2;3;4;2;4;2;2;1;1;2;1;1;2;1;1;1;2;1;2;...                                                                                                                                                                      \n",
            "1  5;4;2;5;2;5;5;3;2;2;2;1;1;2;1;1;2;2;2;3;1;1;3;...                                                                                                                                                                      \n",
            "2  3;2;2;4;1;4;3;2;2;2;2;1;1;4;2;1;1;2;2;2;2;1;2;...                                                                                                                                                                      \n",
            "3  2;4;4;3;2;4;3;3;2;2;3;2;4;4;4;1;3;3;5;4;2;2;4;...                                                                                                                                                                      \n",
            "4  4;3;1;1;2;1;2;5;2;3;2;3;3;2;1;3;5;5;4;3;1;1;5;...                                                                                                                                                                      \n",
            "Data types\n",
            "Mach1 ;Mach2 ;Mach3 ;Mach4 ;Mach5 ;Mach6 ;Mach7 ;Mach8 ;Mach9 ;Psycho1 ;Psycho2 ;Psycho3 ;Psycho4 ;Psycho5 ;Psycho6 ;Psycho7 ;Psycho8 ;Psycho9 ;Narc1 ;Narc2 ;Narc3 ;Narc4 ;Narc5 ;Narc6 ;Narc7 ;Narc8 ;Narc9 ;CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "       Mach1 ;Mach2 ;Mach3 ;Mach4 ;Mach5 ;Mach6 ;Mach7 ;Mach8 ;Mach9 ;Psycho1 ;Psycho2 ;Psycho3 ;Psycho4 ;Psycho5 ;Psycho6 ;Psycho7 ;Psycho8 ;Psycho9 ;Narc1 ;Narc2 ;Narc3 ;Narc4 ;Narc5 ;Narc6 ;Narc7 ;Narc8 ;Narc9 ;CONDITION\n",
            "count                                                 864                                                                                                                                                                      \n",
            "unique                                                850                                                                                                                                                                      \n",
            "top     3;2;2;2;3;3;3;1;4;2;1;2;1;3;4;2;1;1;4;4;2;2;3;...                                                                                                                                                                      \n",
            "freq                                                    2                                                                                                                                                                      \n",
            "Another dataset\n",
            "Data shape\n",
            "(1404, 17)\n",
            "Data head\n",
            "   PRMQ_PR_SH_CU1  PRMQ_RE _LO_ENV2   PRMQ_PR_SH_ENV3  PRMQ_RE_SH_CU4  \\\n",
            "0               4                 3                 2               4   \n",
            "1               3                 1                 1               3   \n",
            "2               3                 2                 2               4   \n",
            "3               4                 1                 2               4   \n",
            "4               4                 3                 3               4   \n",
            "\n",
            "   PRMQ_PR_LO_CU5  PRMQ_RE_SH_ENV6  PRMQ_PR_LO_ENV7  PRMQ_RE_LO_CU8  \\\n",
            "0               4                2                3               2   \n",
            "1               1                4                4               2   \n",
            "2               5                1                1               4   \n",
            "3               3                1                1               3   \n",
            "4               3                2                5               3   \n",
            "\n",
            "   PRMQ_RE_LO_ENV9  PRMQ_PR_SH_ENV10  PRMQ _RE_SH_CU11  PRMQ_PR_LO_ENV12  \\\n",
            "0                3                 3                 4                 4   \n",
            "1                5                 3                 4                 1   \n",
            "2                2                 4                 5                 2   \n",
            "3                4                 3                 4                 3   \n",
            "4                4                 5                 4                 3   \n",
            "\n",
            "   PRMQ _RE_SH_ENV13  PRMQ _PR_LO_CU14  PRMQ_RE_LO_CU15  PRMQ_PR_SH_CU16  \\\n",
            "0                  2                 4                4                4   \n",
            "1                  2                 4                3                4   \n",
            "2                  1                 5                2                4   \n",
            "3                  2                 5                4                4   \n",
            "4                  3                 3                2                5   \n",
            "\n",
            "  CONDITION  \n",
            "0         H  \n",
            "1         H  \n",
            "2         H  \n",
            "3         H  \n",
            "4         H  \n",
            "Data types\n",
            "PRMQ_PR_SH_CU1        int64\n",
            "PRMQ_RE _LO_ENV2      int64\n",
            " PRMQ_PR_SH_ENV3      int64\n",
            "PRMQ_RE_SH_CU4        int64\n",
            "PRMQ_PR_LO_CU5        int64\n",
            "PRMQ_RE_SH_ENV6       int64\n",
            "PRMQ_PR_LO_ENV7       int64\n",
            "PRMQ_RE_LO_CU8        int64\n",
            "PRMQ_RE_LO_ENV9       int64\n",
            "PRMQ_PR_SH_ENV10      int64\n",
            "PRMQ _RE_SH_CU11      int64\n",
            "PRMQ_PR_LO_ENV12      int64\n",
            "PRMQ _RE_SH_ENV13     int64\n",
            "PRMQ _PR_LO_CU14      int64\n",
            "PRMQ_RE_LO_CU15       int64\n",
            "PRMQ_PR_SH_CU16       int64\n",
            "CONDITION            object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "       PRMQ_PR_SH_CU1  PRMQ_RE _LO_ENV2   PRMQ_PR_SH_ENV3  PRMQ_RE_SH_CU4  \\\n",
            "count     1404.000000       1404.000000       1404.000000     1404.000000   \n",
            "mean         3.353989          2.901709          3.147436        3.358974   \n",
            "std          1.380308          1.593920          1.477916        1.416499   \n",
            "min          1.000000          1.000000          1.000000        1.000000   \n",
            "25%          2.000000          1.000000          2.000000        2.000000   \n",
            "50%          4.000000          3.000000          3.000000        4.000000   \n",
            "75%          5.000000          5.000000          5.000000        5.000000   \n",
            "max          5.000000          5.000000          5.000000        5.000000   \n",
            "\n",
            "       PRMQ_PR_LO_CU5  PRMQ_RE_SH_ENV6  PRMQ_PR_LO_ENV7  PRMQ_RE_LO_CU8  \\\n",
            "count     1404.000000      1404.000000      1404.000000     1404.000000   \n",
            "mean         3.284188         2.997151         3.230057        3.151709   \n",
            "std          1.509204         1.550754         1.466347        1.541233   \n",
            "min          1.000000         1.000000         1.000000        1.000000   \n",
            "25%          2.000000         1.000000         2.000000        2.000000   \n",
            "50%          3.000000         3.000000         3.000000        3.000000   \n",
            "75%          5.000000         4.250000         5.000000        5.000000   \n",
            "max          5.000000         5.000000         5.000000        5.000000   \n",
            "\n",
            "       PRMQ_RE_LO_ENV9  PRMQ_PR_SH_ENV10  PRMQ _RE_SH_CU11  PRMQ_PR_LO_ENV12  \\\n",
            "count      1404.000000       1404.000000       1404.000000       1404.000000   \n",
            "mean          3.351140          3.424501          3.458689          3.235755   \n",
            "std           1.443616          1.378223          1.414366          1.383377   \n",
            "min           1.000000          1.000000          1.000000          1.000000   \n",
            "25%           2.000000          2.000000          2.000000          2.000000   \n",
            "50%           4.000000          4.000000          4.000000          3.000000   \n",
            "75%           5.000000          5.000000          5.000000          5.000000   \n",
            "max           5.000000          5.000000          5.000000          5.000000   \n",
            "\n",
            "       PRMQ _RE_SH_ENV13  PRMQ _PR_LO_CU14  PRMQ_RE_LO_CU15  PRMQ_PR_SH_CU16  \n",
            "count        1404.000000       1404.000000      1404.000000      1404.000000  \n",
            "mean            2.979345          3.269231         3.167379         3.406695  \n",
            "std             1.527230          1.455011         1.499742         1.339880  \n",
            "min             1.000000          1.000000         1.000000         1.000000  \n",
            "25%             2.000000          2.000000         2.000000         2.000000  \n",
            "50%             3.000000          3.000000         3.000000         4.000000  \n",
            "75%             4.000000          5.000000         5.000000         5.000000  \n",
            "max             5.000000          5.000000         5.000000         5.000000  \n",
            "Another dataset\n",
            "Data shape\n",
            "(402, 1)\n",
            "Data head\n",
            "  PCL1;PCL2;PCL3;PCL4;PCL5;PCL6;PCL7;PCL8;PCL9;PCL10;PCL11;PCL12;PCL13;PCL14;PCL15;PCL16;PCL17;PCL18;PCL19;PCL20;CONDITION\n",
            "0          1;1;3;2;2;0;1;0;1;2;2;3;2;0;0;1;2;1;0;1;H                                                                      \n",
            "1          0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;H                                                                      \n",
            "2          0;0;0;0;0;0;2;0;3;0;2;3;3;4;0;0;1;0;2;2;H                                                                      \n",
            "3          0;1;0;1;0;0;1;2;1;1;3;2;1;0;2;1;0;0;3;1;H                                                                      \n",
            "4          2;1;1;1;0;3;2;0;2;1;1;1;3;0;1;0;1;1;4;1;H                                                                      \n",
            "Data types\n",
            "PCL1;PCL2;PCL3;PCL4;PCL5;PCL6;PCL7;PCL8;PCL9;PCL10;PCL11;PCL12;PCL13;PCL14;PCL15;PCL16;PCL17;PCL18;PCL19;PCL20;CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "       PCL1;PCL2;PCL3;PCL4;PCL5;PCL6;PCL7;PCL8;PCL9;PCL10;PCL11;PCL12;PCL13;PCL14;PCL15;PCL16;PCL17;PCL18;PCL19;PCL20;CONDITION\n",
            "count                                                 402                                                                      \n",
            "unique                                                358                                                                      \n",
            "top             1;0;1;1;0;2;1;2;1;1;1;0;2;0;0;0;1;0;1;1;H                                                                      \n",
            "freq                                                    3                                                                      \n",
            "Another dataset\n",
            "Data shape\n",
            "(888, 1)\n",
            "Data head\n",
            "  NAQ-R_WR_1;NAQ-R_PR_2;NAQ-R_WR_3;NAQ-R_WR_4;NAQ-R_PR_5;NAQ-R_PR_6;NAQ-R_PR_7;NAQ-R_PI_8;NAQ-R_PI_9;NAQ-R_WR_10;NAQ-R_WR_11;NAQ-R_PR_12;NAQ-R_WR_13;NAQ-R_PR_14;NAQ-R_PI_15;NAQ-R_WR_16;NAQ-R_PR_17;NAQ-R_WR_18;NAQ-R_WR_19;NAQ-R_PR_20;NAQ-R_WR_21;NAQ-R_PI_22;CONDITION\n",
            "0      1;1;3;2;1;1;1;2;1;1;1;1;1;2;1;1;1;2;1;1;1;1;H                                                                                                                                                                                                                      \n",
            "1      1;1;1;1;2;4;1;1;1;1;2;1;1;1;1;1;1;1;1;2;1;1;H                                                                                                                                                                                                                      \n",
            "2      1;1;3;1;1;1;3;4;2;1;3;2;1;3;2;1;1;1;1;2;3;2;H                                                                                                                                                                                                                      \n",
            "3      1;1;1;1;1;1;1;1;1;1;1;1;1;1;1;1;1;1;1;1;1;1;H                                                                                                                                                                                                                      \n",
            "4      1;1;1;1;2;4;3;2;2;1;1;2;1;2;3;1;3;2;1;3;1;1;H                                                                                                                                                                                                                      \n",
            "Data types\n",
            "NAQ-R_WR_1;NAQ-R_PR_2;NAQ-R_WR_3;NAQ-R_WR_4;NAQ-R_PR_5;NAQ-R_PR_6;NAQ-R_PR_7;NAQ-R_PI_8;NAQ-R_PI_9;NAQ-R_WR_10;NAQ-R_WR_11;NAQ-R_PR_12;NAQ-R_WR_13;NAQ-R_PR_14;NAQ-R_PI_15;NAQ-R_WR_16;NAQ-R_PR_17;NAQ-R_WR_18;NAQ-R_WR_19;NAQ-R_PR_20;NAQ-R_WR_21;NAQ-R_PI_22;CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "       NAQ-R_WR_1;NAQ-R_PR_2;NAQ-R_WR_3;NAQ-R_WR_4;NAQ-R_PR_5;NAQ-R_PR_6;NAQ-R_PR_7;NAQ-R_PI_8;NAQ-R_PI_9;NAQ-R_WR_10;NAQ-R_WR_11;NAQ-R_PR_12;NAQ-R_WR_13;NAQ-R_PR_14;NAQ-R_PI_15;NAQ-R_WR_16;NAQ-R_PR_17;NAQ-R_WR_18;NAQ-R_WR_19;NAQ-R_PR_20;NAQ-R_WR_21;NAQ-R_PI_22;CONDITION\n",
            "count                                                 888                                                                                                                                                                                                                      \n",
            "unique                                                772                                                                                                                                                                                                                      \n",
            "top         5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;D                                                                                                                                                                                                                      \n",
            "freq                                                   42                                                                                                                                                                                                                      \n",
            "Another dataset\n",
            "Data shape\n",
            "(1118, 1)\n",
            "Data head\n",
            "  PHQ1;PHQ2;PHQ3;PHQ4;PHQ5;PHQ6;PHQ7;PHQ8;PHQ9;GAD1;GAD2;GAD3;GAD4;GAD5;GAD6;GAD7;CONDITION\n",
            "0                  3;1;1;3;1;1;2;1;2;2;3;2;2;2;3;2;H                                       \n",
            "1                  2;1;3;3;1;1;3;1;5;3;3;3;2;1;3;5;H                                       \n",
            "2                  3;2;2;3;4;3;2;2;2;3;2;3;3;3;3;3;H                                       \n",
            "3                  2;2;4;3;2;4;1;4;4;2;4;4;1;1;1;3;H                                       \n",
            "4                  2;2;5;2;4;3;4;2;4;3;2;5;3;1;5;2;H                                       \n",
            "Data types\n",
            "PHQ1;PHQ2;PHQ3;PHQ4;PHQ5;PHQ6;PHQ7;PHQ8;PHQ9;GAD1;GAD2;GAD3;GAD4;GAD5;GAD6;GAD7;CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "       PHQ1;PHQ2;PHQ3;PHQ4;PHQ5;PHQ6;PHQ7;PHQ8;PHQ9;GAD1;GAD2;GAD3;GAD4;GAD5;GAD6;GAD7;CONDITION\n",
            "count                                                1118                                       \n",
            "unique                                               1016                                       \n",
            "top                     5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;5;D                                       \n",
            "freq                                                   59                                       \n",
            "Another dataset\n",
            "Data shape\n",
            "(824, 1)\n",
            "Data head\n",
            "  Q1;Q2;Q3;Q4;Q5;Q6;Q7;Q8;Q9;Q10;Q11;Q12;Q13;Q14;Q15;Q16;Q17;Q18;Q19;Q20;Q21;Q22;Q23;Q24;Q25;Q26;Q27;Q28;Q29;Q30;Q31;Q32;Q33;Q34;Q35;Q36;Q37;Q38;Q39;Q40;Q41;Q42;Q43;Q44;Q45;Q46;Q47;Q48;Q49;Q50;Q51;Q52;Q53;Q54;Q55;Q56;Q57;Q58;Q59;Q60;Q61;Q62;Q63;Q64;Q65;Q66;Q67;Q68;Q69;Q70;Q71;Q72;Q73;Q74;Q75;Q76;Q77;Q78;Q79;Q80;Q81;Q82;Q83;Q84;Q85;Q86;Q87;Q88;Q89;Q90;Q91;Q92;Q93;Q94;Q95;Q96;Q97;Q98;Q99;Q100;Q101;Q102;Q103;Q104;Q105;Q106;Q107;Q108;Q109;Q110;Q111;Q112;Q113;Q114;Q115;Q116;Q117;Q118;Q119;Q120;Q121;Q122;Q123;Q124;Q125;Q126;Q127;Q128;Q129;Q130;Q131;Q132;Q133;Q134;Q135;Q136;Q137;Q138;Q139;Q140;Q141;Q142;Q143;Q144;Q145;Q146;Q147;Q148;Q149;Q150;Q151;Q152;Q153;Q154;Q155;Q156;Q157;Q158;Q159;Q160;Q161;Q162;Q163;Q164;Q165;Q166;Q167;Q168;Q169;Q170;Q171;Q172;Q173;Q174;Q175;Q176;Q177;Q178;Q179;Q180;Q181;Q182;Q183;Q184;Q185;Q186;Q187;Q188;Q189;Q190;Q191;Q192;Q193;Q194;Q195;Q196;Q197;Q198;Q199;Q200;Q201;Q202;Q203;Q204;Q205;Q206;Q207;Q208;Q209;Q210;Q211;Q212;Q213;Q214;Q215;Q216;Q217;Q218;Q219;Q220;CONDITION\n",
            "0  0;0;2;2;0;0;2;0;0;1;0;0;1;1;1;2;0;1;0;1;0;2;0;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "1  0;1;1;2;2;1;1;0;1;0;0;1;0;1;1;2;2;2;0;2;1;2;0;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "2  1;0;0;1;1;1;2;1;2;1;0;2;1;2;2;1;1;2;1;2;1;1;1;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "3  2;0;1;2;2;2;2;0;2;1;0;3;0;1;1;2;2;2;0;1;2;2;1;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "4  2;0;0;0;1;1;1;0;2;1;0;3;0;1;3;0;0;2;0;2;1;0;1;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "Data types\n",
            "Q1;Q2;Q3;Q4;Q5;Q6;Q7;Q8;Q9;Q10;Q11;Q12;Q13;Q14;Q15;Q16;Q17;Q18;Q19;Q20;Q21;Q22;Q23;Q24;Q25;Q26;Q27;Q28;Q29;Q30;Q31;Q32;Q33;Q34;Q35;Q36;Q37;Q38;Q39;Q40;Q41;Q42;Q43;Q44;Q45;Q46;Q47;Q48;Q49;Q50;Q51;Q52;Q53;Q54;Q55;Q56;Q57;Q58;Q59;Q60;Q61;Q62;Q63;Q64;Q65;Q66;Q67;Q68;Q69;Q70;Q71;Q72;Q73;Q74;Q75;Q76;Q77;Q78;Q79;Q80;Q81;Q82;Q83;Q84;Q85;Q86;Q87;Q88;Q89;Q90;Q91;Q92;Q93;Q94;Q95;Q96;Q97;Q98;Q99;Q100;Q101;Q102;Q103;Q104;Q105;Q106;Q107;Q108;Q109;Q110;Q111;Q112;Q113;Q114;Q115;Q116;Q117;Q118;Q119;Q120;Q121;Q122;Q123;Q124;Q125;Q126;Q127;Q128;Q129;Q130;Q131;Q132;Q133;Q134;Q135;Q136;Q137;Q138;Q139;Q140;Q141;Q142;Q143;Q144;Q145;Q146;Q147;Q148;Q149;Q150;Q151;Q152;Q153;Q154;Q155;Q156;Q157;Q158;Q159;Q160;Q161;Q162;Q163;Q164;Q165;Q166;Q167;Q168;Q169;Q170;Q171;Q172;Q173;Q174;Q175;Q176;Q177;Q178;Q179;Q180;Q181;Q182;Q183;Q184;Q185;Q186;Q187;Q188;Q189;Q190;Q191;Q192;Q193;Q194;Q195;Q196;Q197;Q198;Q199;Q200;Q201;Q202;Q203;Q204;Q205;Q206;Q207;Q208;Q209;Q210;Q211;Q212;Q213;Q214;Q215;Q216;Q217;Q218;Q219;Q220;CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "       Q1;Q2;Q3;Q4;Q5;Q6;Q7;Q8;Q9;Q10;Q11;Q12;Q13;Q14;Q15;Q16;Q17;Q18;Q19;Q20;Q21;Q22;Q23;Q24;Q25;Q26;Q27;Q28;Q29;Q30;Q31;Q32;Q33;Q34;Q35;Q36;Q37;Q38;Q39;Q40;Q41;Q42;Q43;Q44;Q45;Q46;Q47;Q48;Q49;Q50;Q51;Q52;Q53;Q54;Q55;Q56;Q57;Q58;Q59;Q60;Q61;Q62;Q63;Q64;Q65;Q66;Q67;Q68;Q69;Q70;Q71;Q72;Q73;Q74;Q75;Q76;Q77;Q78;Q79;Q80;Q81;Q82;Q83;Q84;Q85;Q86;Q87;Q88;Q89;Q90;Q91;Q92;Q93;Q94;Q95;Q96;Q97;Q98;Q99;Q100;Q101;Q102;Q103;Q104;Q105;Q106;Q107;Q108;Q109;Q110;Q111;Q112;Q113;Q114;Q115;Q116;Q117;Q118;Q119;Q120;Q121;Q122;Q123;Q124;Q125;Q126;Q127;Q128;Q129;Q130;Q131;Q132;Q133;Q134;Q135;Q136;Q137;Q138;Q139;Q140;Q141;Q142;Q143;Q144;Q145;Q146;Q147;Q148;Q149;Q150;Q151;Q152;Q153;Q154;Q155;Q156;Q157;Q158;Q159;Q160;Q161;Q162;Q163;Q164;Q165;Q166;Q167;Q168;Q169;Q170;Q171;Q172;Q173;Q174;Q175;Q176;Q177;Q178;Q179;Q180;Q181;Q182;Q183;Q184;Q185;Q186;Q187;Q188;Q189;Q190;Q191;Q192;Q193;Q194;Q195;Q196;Q197;Q198;Q199;Q200;Q201;Q202;Q203;Q204;Q205;Q206;Q207;Q208;Q209;Q210;Q211;Q212;Q213;Q214;Q215;Q216;Q217;Q218;Q219;Q220;CONDITION\n",
            "count                                                 824                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "unique                                                824                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "top     0;0;2;2;0;0;2;0;0;1;0;0;1;1;1;2;0;1;0;1;0;2;0;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "freq                                                    1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "Another dataset\n",
            "Data shape\n",
            "(1038, 26)\n",
            "Data head\n",
            "   PID1  PID2  PID3  PID4  PID5  PID6  PID7  PID8  PID9  PID10  ...  PID17  \\\n",
            "0     1     4     3     2     1     3     3     4     4      3  ...      1   \n",
            "1     3     3     4     4     1     1     3     4     4      2  ...      1   \n",
            "2     3     2     1     2     1     1     2     4     4      3  ...      2   \n",
            "3     1     1     1     2     1     2     2     3     3      1  ...      1   \n",
            "4     3     3     2     1     3     2     1     2     2      1  ...      2   \n",
            "\n",
            "   PID18  PID19  PID20  PID21  PID22  PID23  PID24  PID25  CONDITION  \n",
            "0      4      4      2      1      2      1      2      1          H  \n",
            "1      1      4      3      2      1      1      1      3          H  \n",
            "2      2      3      3      2      3      1      1      2          H  \n",
            "3      1      1      2      1      1      1      1      1          H  \n",
            "4      2      3      3      1      3      1      1      3          H  \n",
            "\n",
            "[5 rows x 26 columns]\n",
            "Data types\n",
            "PID1          int64\n",
            "PID2          int64\n",
            "PID3          int64\n",
            "PID4          int64\n",
            "PID5          int64\n",
            "PID6          int64\n",
            "PID7          int64\n",
            "PID8          int64\n",
            "PID9          int64\n",
            "PID10         int64\n",
            "PID11         int64\n",
            "PID12         int64\n",
            "PID13         int64\n",
            "PID14         int64\n",
            "PID15         int64\n",
            "PID16         int64\n",
            "PID17         int64\n",
            "PID18         int64\n",
            "PID19         int64\n",
            "PID20         int64\n",
            "PID21         int64\n",
            "PID22         int64\n",
            "PID23         int64\n",
            "PID24         int64\n",
            "PID25         int64\n",
            "CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "              PID1         PID2         PID3         PID4         PID5  \\\n",
            "count  1038.000000  1038.000000  1038.000000  1038.000000  1038.000000   \n",
            "mean      2.438343     2.626204     2.394027     2.598266     2.202312   \n",
            "std       1.190429     1.184506     1.223304     1.095919     1.271115   \n",
            "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
            "25%       1.000000     2.000000     1.000000     2.000000     1.000000   \n",
            "50%       3.000000     3.000000     2.000000     3.000000     2.000000   \n",
            "75%       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
            "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
            "\n",
            "              PID6         PID7         PID8         PID9        PID10  ...  \\\n",
            "count  1038.000000  1038.000000  1038.000000  1038.000000  1038.000000  ...   \n",
            "mean      2.444123     2.623314     2.607900     2.933526     2.657996  ...   \n",
            "std       1.130049     1.178281     1.109882     1.012179     1.157587  ...   \n",
            "min       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
            "25%       1.000000     1.000000     2.000000     2.000000     2.000000  ...   \n",
            "50%       2.000000     3.000000     3.000000     3.000000     3.000000  ...   \n",
            "75%       3.000000     4.000000     4.000000     4.000000     4.000000  ...   \n",
            "max       4.000000     4.000000     4.000000     4.000000     4.000000  ...   \n",
            "\n",
            "             PID16        PID17        PID18        PID19        PID20  \\\n",
            "count  1038.000000  1038.000000  1038.000000  1038.000000  1038.000000   \n",
            "mean      2.316956     2.200385     2.182081     2.631021     2.325626   \n",
            "std       1.123400     1.275963     1.143759     1.148426     1.222553   \n",
            "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
            "25%       1.000000     1.000000     1.000000     2.000000     1.000000   \n",
            "50%       2.000000     2.000000     2.000000     3.000000     2.000000   \n",
            "75%       3.000000     4.000000     3.000000     4.000000     4.000000   \n",
            "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
            "\n",
            "             PID21        PID22        PID23        PID24        PID25  \n",
            "count  1038.000000  1038.000000  1038.000000  1038.000000  1038.000000  \n",
            "mean      2.556840     2.187861     2.475915     2.383430     2.114644  \n",
            "std       1.299858     1.243059     1.293444     1.341926     1.246541  \n",
            "min       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
            "25%       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
            "50%       3.000000     2.000000     3.000000     2.000000     2.000000  \n",
            "75%       4.000000     4.000000     4.000000     4.000000     3.000000  \n",
            "max       4.000000     4.000000     4.000000     4.000000     4.000000  \n",
            "\n",
            "[8 rows x 25 columns]\n",
            "Another dataset\n",
            "Data shape\n",
            "(678, 19)\n",
            "Data head\n",
            "   PreM1  PreM2  PreM3  PreM4  PreM5  PreM6  C1  C2  C3  C4  C5  C6  IC1  IC2  \\\n",
            "0      2      1      4      1      2      1   4   3   4   3   4   4    3    2   \n",
            "1      1      1      5      1      1      1   1   1   1   1   5   1    5    5   \n",
            "2      1      1      1      1      1      1   3   3   3   3   5   3    5    4   \n",
            "3      4      2      5      1      1      1   4   1   1   3   3   1    3    3   \n",
            "4      1      1      3      1      1      1   3   3   2   5   5   3    4    3   \n",
            "\n",
            "   IC3  IC4  IC5  IC6 CONDITION  \n",
            "0    2    2    3    4         H  \n",
            "1    5    3    5    5         H  \n",
            "2    5    5    5    5         H  \n",
            "3    4    1    3    1         H  \n",
            "4    3    3    4    5         H  \n",
            "Data types\n",
            "PreM1         int64\n",
            "PreM2         int64\n",
            "PreM3         int64\n",
            "PreM4         int64\n",
            "PreM5         int64\n",
            "PreM6         int64\n",
            "C1            int64\n",
            "C2            int64\n",
            "C3            int64\n",
            "C4            int64\n",
            "C5            int64\n",
            "C6            int64\n",
            "IC1           int64\n",
            "IC2           int64\n",
            "IC3           int64\n",
            "IC4           int64\n",
            "IC5           int64\n",
            "IC6           int64\n",
            "CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "            PreM1       PreM2       PreM3       PreM4       PreM5       PreM6  \\\n",
            "count  678.000000  678.000000  678.000000  678.000000  678.000000  678.000000   \n",
            "mean     1.747788    1.283186    1.945428    1.268437    1.318584    1.615044   \n",
            "std      1.319030    0.886155    1.324121    0.843031    0.848307    1.045866   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "50%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "75%      2.000000    1.000000    3.000000    1.000000    1.000000    2.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "               C1          C2          C3          C4          C5          C6  \\\n",
            "count  678.000000  678.000000  678.000000  678.000000  678.000000  678.000000   \n",
            "mean     3.730088    3.449853    3.613569    3.222714    4.147493    3.612094   \n",
            "std      1.279082    1.457317    1.365731    1.472229    1.079725    1.353905   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      3.000000    2.000000    3.000000    2.000000    3.000000    3.000000   \n",
            "50%      4.000000    4.000000    4.000000    3.000000    5.000000    4.000000   \n",
            "75%      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "              IC1         IC2         IC3         IC4         IC5         IC6  \n",
            "count  678.000000  678.000000  678.000000  678.000000  678.000000  678.000000  \n",
            "mean     4.541298    4.305310    4.539823    4.379056    4.584071    4.342183  \n",
            "std      0.826396    1.035415    0.840645    0.886117    0.773173    1.249291  \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  \n",
            "25%      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000  \n",
            "50%      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000  \n",
            "75%      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000  \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000  \n",
            "Another dataset\n",
            "Data shape\n",
            "(358, 23)\n",
            "Data head\n",
            "   IESR1  IESR2  IESR3  IESR4  IESR5  IESR6  IESR7  IESR8  IESR9  IESR10  ...  \\\n",
            "0      1      1      1      1      1      1      1      1      1       1  ...   \n",
            "1      1      1      1      1      1      1      1      1      1       1  ...   \n",
            "2      1      1      1      1      1      1      1      1      1       1  ...   \n",
            "3      1      1      1      1      1      1      1      1      1       1  ...   \n",
            "4      1      1      1      1      1      1      1      1      1       1  ...   \n",
            "\n",
            "   IESR14  IESR15  IESR16  IESR17  IESR18  IESR19  IESR20  IESR21  IESR22  \\\n",
            "0       1       1       1       1       1       1       1       1       1   \n",
            "1       1       1       1       1       1       1       1       1       1   \n",
            "2       1       1       1       1       1       1       1       1       1   \n",
            "3       1       1       1       1       1       1       1       1       1   \n",
            "4       1       1       1       1       1       1       1       1       1   \n",
            "\n",
            "   CONDITION  \n",
            "0          H  \n",
            "1          H  \n",
            "2          H  \n",
            "3          H  \n",
            "4          H  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "Data types\n",
            "IESR1         int64\n",
            "IESR2         int64\n",
            "IESR3         int64\n",
            "IESR4         int64\n",
            "IESR5         int64\n",
            "IESR6         int64\n",
            "IESR7         int64\n",
            "IESR8         int64\n",
            "IESR9         int64\n",
            "IESR10        int64\n",
            "IESR11        int64\n",
            "IESR12        int64\n",
            "IESR13        int64\n",
            "IESR14        int64\n",
            "IESR15        int64\n",
            "IESR16        int64\n",
            "IESR17        int64\n",
            "IESR18        int64\n",
            "IESR19        int64\n",
            "IESR20        int64\n",
            "IESR21        int64\n",
            "IESR22        int64\n",
            "CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "            IESR1       IESR2       IESR3       IESR4       IESR5       IESR6  \\\n",
            "count  358.000000  358.000000  358.000000  358.000000  358.000000  358.000000   \n",
            "mean     3.209497    2.631285    2.963687    2.913408    2.698324    3.259777   \n",
            "std      1.340270    1.540608    1.335287    1.353816    1.302249    1.490249   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      2.000000    1.000000    2.000000    2.000000    2.000000    2.000000   \n",
            "50%      4.000000    2.000000    3.000000    3.000000    3.000000    3.500000   \n",
            "75%      4.000000    4.000000    4.000000    4.000000    4.000000    5.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "            IESR7       IESR8       IESR9      IESR10  ...      IESR13  \\\n",
            "count  358.000000  358.000000  358.000000  358.000000  ...  358.000000   \n",
            "mean     2.402235    2.893855    2.907821    2.955307  ...    2.472067   \n",
            "std      1.435912    1.580666    1.665230    1.425346  ...    1.483070   \n",
            "min      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
            "25%      1.000000    1.000000    1.000000    2.000000  ...    1.000000   \n",
            "50%      2.000000    3.000000    3.000000    3.000000  ...    2.000000   \n",
            "75%      4.000000    4.000000    5.000000    4.000000  ...    4.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000  ...    5.000000   \n",
            "\n",
            "           IESR14      IESR15      IESR16      IESR17      IESR18      IESR19  \\\n",
            "count  358.000000  358.000000  358.000000  358.000000  358.000000  358.000000   \n",
            "mean     2.871508    2.826816    3.125698    2.762570    2.782123    2.717877   \n",
            "std      1.631354    1.664645    1.535156    1.597283    1.509081    1.718661   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      1.000000    1.000000    2.000000    1.000000    1.000000    1.000000   \n",
            "50%      3.000000    3.000000    3.000000    3.000000    3.000000    2.000000   \n",
            "75%      4.000000    5.000000    5.000000    4.000000    4.000000    5.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "           IESR20      IESR21      IESR22  \n",
            "count  358.000000  358.000000  358.000000  \n",
            "mean     2.913408    2.723464    2.737430  \n",
            "std      1.619485    1.498480    1.529649  \n",
            "min      1.000000    1.000000    1.000000  \n",
            "25%      1.000000    1.000000    1.000000  \n",
            "50%      3.000000    3.000000    2.500000  \n",
            "75%      5.000000    4.000000    4.000000  \n",
            "max      5.000000    5.000000    5.000000  \n",
            "\n",
            "[8 rows x 22 columns]\n",
            "Another dataset\n",
            "Data shape\n",
            "(10514, 30)\n",
            "Data head\n",
            "  ESTROVERSIONE          Unnamed: 1 Unnamed: 2   Unnamed: 3    Unnamed: 4  \\\n",
            "0     Ottimismo  Ricerca di stimoli   Attività  Assertività  Socievolezza   \n",
            "1            15                  12         14           12            13   \n",
            "2            18                  17         16           12            18   \n",
            "3            16                   8         16           17            15   \n",
            "4            18                   9         17           14            11   \n",
            "\n",
            "   Unnamed: 5 AMICALITA'    Unnamed: 7    Unnamed: 8 Unnamed: 9  ...  \\\n",
            "0  Cordialità    Empatia  Riservatezza  Cooperazione  Altruismo  ...   \n",
            "1          15         18            15            14         14  ...   \n",
            "2          12         11            17            15         12  ...   \n",
            "3          19         15            13            13         17  ...   \n",
            "4          17         17            14            12         12  ...   \n",
            "\n",
            "            Unnamed: 20 Unnamed: 21 Unnamed: 22 Unnamed: 23 APERTURA MENTALE  \\\n",
            "0  Fiducia in sé stessi   Stabilità   Freddezza       Calma      Liberalismo   \n",
            "1                    10          15          14           8               10   \n",
            "2                    13          10          16          12               13   \n",
            "3                    19          19          20          17               14   \n",
            "4                    19          19          20          19               10   \n",
            "\n",
            "       Unnamed: 25 Unnamed: 26   Unnamed: 27          Unnamed: 28  \\\n",
            "0  Intellettualità     Audacia  Emozionalità  Interessi artistici   \n",
            "1               15          10            13                   14   \n",
            "2               12          17            13                   16   \n",
            "3               19          17            18                   15   \n",
            "4               18          15            17                   14   \n",
            "\n",
            "     Unnamed: 29  \n",
            "0  Immaginazione  \n",
            "1             16  \n",
            "2             17  \n",
            "3             14  \n",
            "4             14  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "Data types\n",
            "ESTROVERSIONE         object\n",
            "Unnamed: 1            object\n",
            "Unnamed: 2            object\n",
            "Unnamed: 3            object\n",
            "Unnamed: 4            object\n",
            "Unnamed: 5            object\n",
            "AMICALITA'            object\n",
            "Unnamed: 7            object\n",
            "Unnamed: 8            object\n",
            "Unnamed: 9            object\n",
            "Unnamed: 10           object\n",
            "Unnamed: 11           object\n",
            "COSCIENZIOSITA'       object\n",
            "Unnamed: 13           object\n",
            "Unnamed: 14           object\n",
            "Unnamed: 15           object\n",
            "Unnamed: 16           object\n",
            "Unnamed: 17           object\n",
            "EQUILIBRIO EMOTIVO    object\n",
            "Unnamed: 19           object\n",
            "Unnamed: 20           object\n",
            "Unnamed: 21           object\n",
            "Unnamed: 22           object\n",
            "Unnamed: 23           object\n",
            "APERTURA MENTALE      object\n",
            "Unnamed: 25           object\n",
            "Unnamed: 26           object\n",
            "Unnamed: 27           object\n",
            "Unnamed: 28           object\n",
            "Unnamed: 29           object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "        ESTROVERSIONE  Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4  \\\n",
            "count           10514       10514       10514       10514       10514   \n",
            "unique             18          18          18          18          18   \n",
            "top                16          12          12          12          12   \n",
            "freq             1262        1263        1571        1494        1412   \n",
            "\n",
            "        Unnamed: 5  AMICALITA'  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  \\\n",
            "count        10514       10514       10514       10514       10514  ...   \n",
            "unique          18          18          18          18          18  ...   \n",
            "top             12          14          12          12          16  ...   \n",
            "freq          1204        1394        1475        1512        1381  ...   \n",
            "\n",
            "        Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  APERTURA MENTALE  \\\n",
            "count         10514        10514        10514        10514             10514   \n",
            "unique           18           18           18           18                18   \n",
            "top              12           12           12           12                12   \n",
            "freq           1492         1062         1311         1428              1651   \n",
            "\n",
            "        Unnamed: 25  Unnamed: 26  Unnamed: 27  Unnamed: 28  Unnamed: 29  \n",
            "count         10514        10514        10514        10514        10514  \n",
            "unique           18           18           18           18           18  \n",
            "top              14           16           16           16           20  \n",
            "freq           1183         1491         1639         1324         1466  \n",
            "\n",
            "[4 rows x 30 columns]\n",
            "Another dataset\n",
            "Data shape\n",
            "(986, 13)\n",
            "Data head\n",
            "   P1  N2  P3  M4  P5  M6  N7  N8  M9  P10  M11  N12 CONDITION\n",
            "0   2   4   1   1   1   1   1   4   2    3    1    1         H\n",
            "1   2   3   2   1   1   1   2   4   1    1    1    3         H\n",
            "2   1   3   1   2   1   1   2   3   3    1    2    2         H\n",
            "3   2   4   2   3   2   2   3   4   2    4    3    4         H\n",
            "4   1   2   1   1   2   2   3   1   1    1    1    2         H\n",
            "Data types\n",
            "P1            int64\n",
            "N2            int64\n",
            "P3            int64\n",
            "M4            int64\n",
            "P5            int64\n",
            "M6            int64\n",
            "N7            int64\n",
            "N8            int64\n",
            "M9            int64\n",
            "P10           int64\n",
            "M11           int64\n",
            "N12           int64\n",
            "CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "               P1          N2          P3          M4          P5          M6  \\\n",
            "count  986.000000  986.000000  986.000000  986.000000  986.000000  986.000000   \n",
            "mean     2.749493    2.715010    1.687627    1.944219    1.625761    1.671400   \n",
            "std      1.357485    1.117883    1.008486    1.175007    1.020056    1.006342   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      2.000000    2.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "50%      2.000000    3.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "75%      4.000000    4.000000    2.000000    3.000000    2.000000    2.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "               N7          N8          M9         P10         M11         N12  \n",
            "count  986.000000  986.000000  986.000000  986.000000  986.000000  986.000000  \n",
            "mean     2.423935    2.949290    1.594320    2.292089    1.756592    2.066937  \n",
            "std      1.162352    1.192815    0.899931    1.176711    1.099876    1.010394  \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  \n",
            "25%      1.000000    2.000000    1.000000    1.000000    1.000000    1.000000  \n",
            "50%      2.000000    3.000000    1.000000    2.000000    1.000000    2.000000  \n",
            "75%      3.000000    4.000000    2.000000    3.000000    2.000000    3.000000  \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000  \n",
            "Another dataset\n",
            "Data shape\n",
            "(450, 10)\n",
            "Data head\n",
            "   Pr1  Pr2  Pr3  FA1  FA2  FA3  FI1  FI2  FI3 CONDITION\n",
            "0    4    2    3    2    2    2    2    2    1         H\n",
            "1    2    3    2    3    2    1    3    2    3         H\n",
            "2    4    3    3    4    4    4    3    3    3         H\n",
            "3    3    3    2    1    3    2    3    2    3         H\n",
            "4    3    2    2    3    3    3    4    3    3         H\n",
            "Data types\n",
            "Pr1           int64\n",
            "Pr2           int64\n",
            "Pr3           int64\n",
            "FA1           int64\n",
            "FA2           int64\n",
            "FA3           int64\n",
            "FI1           int64\n",
            "FI2           int64\n",
            "FI3           int64\n",
            "CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "              Pr1         Pr2         Pr3         FA1         FA2         FA3  \\\n",
            "count  450.000000  450.000000  450.000000  450.000000  450.000000  450.000000   \n",
            "mean     3.128889    3.091111    3.177778    2.875556    3.171111    3.140000   \n",
            "std      1.006133    1.112056    1.027222    1.204142    1.029438    1.021135   \n",
            "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      3.000000    2.000000    3.000000    2.000000    3.000000    3.000000   \n",
            "50%      3.000000    3.000000    3.000000    3.000000    3.000000    3.000000   \n",
            "75%      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
            "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
            "\n",
            "              FI1         FI2         FI3  \n",
            "count  450.000000  450.000000  450.000000  \n",
            "mean     2.962222    3.133333    2.982222  \n",
            "std      1.212737    1.038244    1.104615  \n",
            "min      0.000000    0.000000    0.000000  \n",
            "25%      2.000000    3.000000    2.000000  \n",
            "50%      3.000000    3.000000    3.000000  \n",
            "75%      4.000000    4.000000    4.000000  \n",
            "max      4.000000    4.000000    4.000000  \n",
            "Another dataset\n",
            "Data shape\n",
            "(442, 11)\n",
            "Data head\n",
            "   EX1G  EX2G  A1G  A2G  C1G  C2G  ES1G  ES2G  O1G  O2G CONDITION\n",
            "0     4     4    4    4    4    5     4     4    4    4         H\n",
            "1     4     2    2    4    4    5     3     4    4    4         H\n",
            "2     4     2    2    4    4    4     3     4    4    4         H\n",
            "3     4     2    2    4    2    4     5     5    4    2         H\n",
            "4     3     2    3    4    5    5     4     4    5    5         H\n",
            "Data types\n",
            "EX1G          int64\n",
            "EX2G          int64\n",
            "A1G           int64\n",
            "A2G           int64\n",
            "C1G           int64\n",
            "C2G           int64\n",
            "ES1G          int64\n",
            "ES2G          int64\n",
            "O1G           int64\n",
            "O2G           int64\n",
            "CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "             EX1G        EX2G         A1G         A2G         C1G         C2G  \\\n",
            "count  442.000000  442.000000  442.000000  442.000000  442.000000  442.000000   \n",
            "mean     4.167421    2.316742    3.434389    3.556561    3.789593    4.533937   \n",
            "std      0.861906    0.954350    1.084416    0.946513    1.220973    0.749892   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      4.000000    2.000000    3.000000    3.000000    3.000000    4.000000   \n",
            "50%      4.000000    2.000000    4.000000    4.000000    4.000000    5.000000   \n",
            "75%      5.000000    3.000000    4.000000    4.000000    5.000000    5.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "             ES1G        ES2G         O1G         O2G  \n",
            "count  442.000000  442.000000  442.000000  442.000000  \n",
            "mean     3.642534    3.619910    3.472851    3.649321  \n",
            "std      1.252227    1.199154    1.178198    1.155333  \n",
            "min      1.000000    1.000000    1.000000    1.000000  \n",
            "25%      3.000000    3.000000    3.000000    3.000000  \n",
            "50%      4.000000    4.000000    4.000000    4.000000  \n",
            "75%      5.000000    5.000000    4.000000    4.000000  \n",
            "max      5.000000    5.000000    5.000000    5.000000  \n",
            "Another dataset\n",
            "Data shape\n",
            "(460, 11)\n",
            "Data head\n",
            "   EX1G  EX2G  A1G  A2G  C1G  C2G  ES1G  ES2G  O1G  O2G CONDITION\n",
            "0     3     2    3    3    4    4     2     3    3    3         H\n",
            "1     4     4    4    4    5    5     4     4    4    4         H\n",
            "2     4     2    2    4    4    5     3     4    4    4         H\n",
            "3     4     3    2    4    4    4     3     4    4    4         H\n",
            "4     5     3    3    1    5    5     3     1    3    3         H\n",
            "Data types\n",
            "EX1G          int64\n",
            "EX2G          int64\n",
            "A1G           int64\n",
            "A2G           int64\n",
            "C1G           int64\n",
            "C2G           int64\n",
            "ES1G          int64\n",
            "ES2G          int64\n",
            "O1G           int64\n",
            "O2G           int64\n",
            "CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "             EX1G        EX2G         A1G         A2G         C1G         C2G  \\\n",
            "count  460.000000  460.000000  460.000000  460.000000  460.000000  460.000000   \n",
            "mean     4.152174    2.536957    3.471739    3.756522    3.836957    4.530435   \n",
            "std      0.982802    1.160696    1.201517    0.973204    1.261783    0.790154   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      4.000000    2.000000    2.000000    3.000000    3.000000    4.000000   \n",
            "50%      4.000000    2.000000    4.000000    4.000000    4.000000    5.000000   \n",
            "75%      5.000000    3.000000    4.000000    4.000000    5.000000    5.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "             ES1G        ES2G         O1G         O2G  \n",
            "count  460.000000  460.000000  460.000000  460.000000  \n",
            "mean     3.586957    3.673913    3.828261    3.752174  \n",
            "std      1.277867    1.239410    1.098060    1.180587  \n",
            "min      1.000000    1.000000    1.000000    1.000000  \n",
            "25%      2.000000    3.000000    3.000000    3.000000  \n",
            "50%      4.000000    4.000000    4.000000    4.000000  \n",
            "75%      5.000000    5.000000    5.000000    5.000000  \n",
            "max      5.000000    5.000000    5.000000    5.000000  \n",
            "Another dataset\n",
            "Data shape\n",
            "(486, 11)\n",
            "Data head\n",
            "   EX1G  EX2G  A1G  A2G  C1G  C2G  ES1G  ES2G  O1G  O2G CONDITION\n",
            "0     4     4    4    4    5    5     4     4    4    5         H\n",
            "1     4     3    3    4    4    4     3     3    3    5         H\n",
            "2     4     4    2    3    2    5     4     3    2    1         H\n",
            "3     4     4    2    3    2    5     4     3    2    1         H\n",
            "4     4     2    2    3    1    5     2     3    5    5         H\n",
            "Data types\n",
            "EX1G          int64\n",
            "EX2G          int64\n",
            "A1G           int64\n",
            "A2G           int64\n",
            "C1G           int64\n",
            "C2G           int64\n",
            "ES1G          int64\n",
            "ES2G          int64\n",
            "O1G           int64\n",
            "O2G           int64\n",
            "CONDITION    object\n",
            "dtype: object\n",
            "Description of dataset\n",
            "             EX1G        EX2G         A1G         A2G         C1G         C2G  \\\n",
            "count  486.000000  486.000000  486.000000  486.000000  486.000000  486.000000   \n",
            "mean     4.111111    2.594650    3.205761    3.454733    3.866255    4.572016   \n",
            "std      0.969642    1.185084    1.142816    1.047829    1.222054    0.758430   \n",
            "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "25%      4.000000    2.000000    2.000000    3.000000    3.000000    4.000000   \n",
            "50%      4.000000    2.000000    3.000000    4.000000    4.000000    5.000000   \n",
            "75%      5.000000    4.000000    4.000000    4.000000    5.000000    5.000000   \n",
            "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
            "\n",
            "             ES1G        ES2G         O1G         O2G  \n",
            "count  486.000000  486.000000  486.000000  486.000000  \n",
            "mean     3.458848    3.656379    3.874486    3.648148  \n",
            "std      1.330589    1.251486    1.079656    1.222498  \n",
            "min      1.000000    1.000000    1.000000    1.000000  \n",
            "25%      2.000000    3.000000    3.000000    3.000000  \n",
            "50%      4.000000    4.000000    4.000000    4.000000  \n",
            "75%      5.000000    5.000000    5.000000    5.000000  \n",
            "max      5.000000    5.000000    5.000000    5.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeuZaFlmsW7b"
      },
      "source": [
        "##Cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to extract the pointer's name\n",
        "def get_var_name(variable):\n",
        "    globals_dict = globals()\n",
        "    return [var_name for var_name in globals_dict if globals_dict[var_name] is variable]"
      ],
      "metadata": {
        "id": "1f6eNGlmAu2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting NA values in each dataframe\n",
        "for df in df_list:\n",
        "  print (f'The dataframe {get_var_name(df)[0]} has {df.isna().sum().sum()} NA values out of {df.size} elements')"
      ],
      "metadata": {
        "id": "Z_e1uU3BKiNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90b349f-3325-4423-8346-44fcf80eb79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataframe df_1_DT_df_CC has 0 NA values out of 13496 elements\n",
            "The dataframe df_1_DT_df_JI has 0 NA values out of 864 elements\n",
            "The dataframe df_2_PRMQ_df has 0 NA values out of 23868 elements\n",
            "The dataframe df_3_PCL5_df has 0 NA values out of 402 elements\n",
            "The dataframe df_4_NAQ_R_df has 0 NA values out of 888 elements\n",
            "The dataframe df_5_PHQ9_GAD7_df has 0 NA values out of 1118 elements\n",
            "The dataframe df_6_PID5_df has 0 NA values out of 824 elements\n",
            "The dataframe df_7_sPID5_df has 0 NA values out of 26988 elements\n",
            "The dataframe df_8_PRFQ_df has 0 NA values out of 12882 elements\n",
            "The dataframe df_9_IESR_df has 0 NA values out of 8234 elements\n",
            "The dataframe df_10_Honest has 0 NA values out of 315420 elements\n",
            "The dataframe df_11_RAW_DDDT has 0 NA values out of 12818 elements\n",
            "The dataframe df_12_IADQ_df has 0 NA values out of 4500 elements\n",
            "The dataframe df_13_BF_df_CTU has 0 NA values out of 4862 elements\n",
            "The dataframe df_13_BF_df_OU has 0 NA values out of 5060 elements\n",
            "The dataframe df_13_df_V has 0 NA values out of 5346 elements\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UtpY36hWE35"
      },
      "outputs": [],
      "source": [
        "#data cleaning\n",
        "for l in df_list:\n",
        "  l.dropna() #dropping NA values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlDGMRcBDV3R"
      },
      "source": [
        "##Preprocessing and splitting function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSFeAN_rhX9p"
      },
      "outputs": [],
      "source": [
        "def split(df):\n",
        "  \n",
        "  # split into dependent and independent sets\n",
        "  X, y = df.iloc[:, :-2].values, df.iloc[:, -1].values\n",
        "\n",
        "  # Change response to binary 0 and 1\n",
        "  np.place(y, y=='H', 1)\n",
        "  np.place(y, y=='D', 0)\n",
        "\n",
        "  #splitting the original dataset\n",
        "  X_train , X_test, y_train , y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "\n",
        "  #Scaling the dataset\n",
        "  scaler=Normalizer().fit(X_train)\n",
        "  X_train=scaler.transform(X_train)\n",
        "  X_test=scaler.transform(X_test)\n",
        "\n",
        "  #we change type from 'object' to 'int' so that our study recognizes it\n",
        "  y_train=y_train.astype('int')\n",
        "  y_test=y_test.astype('int')\n",
        "  return X, y, X_train , X_test, y_train , y_test \n",
        "\n",
        "#X_train , X_test, y_train , y_test = split(df) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtUcaOCrxyxV"
      },
      "source": [
        "#Defining objectives for our models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "4I6WZCGoThBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g77YgnMgxzrq"
      },
      "outputs": [],
      "source": [
        "#SVM tuning \n",
        "def objective_SVM(trial):\n",
        "    kernel=trial.suggest_categorical('kernel',['poly','linear','sigmoid'])\n",
        "    c=trial.suggest_float(\"C\",0.1,3.0,log=True)\n",
        "    gamma=trial.suggest_categorical('gamma',['auto','scale'])\n",
        "    degree=trial.suggest_int(\"degree\",1,3,log=True)\n",
        "    #probability = trial.set_user_attr(\"probability\",True)\n",
        "    m =svm.SVC(kernel=kernel,degree=degree,gamma=gamma,C=c, probability = True)\n",
        "    m.fit(X_train,y_train)\n",
        "    return cross_val_score(m, X_train, y_train, n_jobs=-1, cv=5).mean()\n",
        "\n",
        "#K-NN tuning\n",
        "def objective_KNN(trial):\n",
        "    n_neighbors = trial.suggest_int(\"n_neighbors\", 5, 10)\n",
        "    weights = trial.suggest_categorical(\"weights\", ['uniform', 'distance'])\n",
        "    metric = trial.suggest_categorical(\"metric\", ['euclidean', 'manhattan', 'minkowski'])\n",
        "    m = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric)\n",
        "    m.fit(X_train,y_train)\n",
        "    score =  cross_val_score(m, X_train, y_train, n_jobs=-1, cv=5).mean() \n",
        "    return score\n",
        "#RF tuning\n",
        "def objective_RF(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 2, 20)\n",
        "    max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
        "    m = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "    return cross_val_score(m, X_train, y_train, n_jobs=-1, cv=5).mean()\n",
        "\n",
        "#Tree tuning\n",
        "def objective_T(trial):\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 20)\n",
        "    m = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split,\n",
        "                               min_samples_leaf=min_samples_leaf)\n",
        "    return cross_val_score(m, X_train, y_train, n_jobs=-1, cv=5).mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelling function"
      ],
      "metadata": {
        "id": "WLQ2RSm0Ni5J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMvvEJXLnd5O"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#Modelling function\n",
        "def modelling(model, X_train, X_val, y_train, y_val, hyper = None,  tuning = False, flow = False, n = 20):\n",
        "#decide later on what plots to show for tuning and read about types of samplers\n",
        "  if tuning == True:\n",
        "    study = op.create_study(direction=\"maximize\")\n",
        "    if model=='KNN':\n",
        "      study.optimize(objective_KNN, n_trials = n ,n_jobs=-1) #number of trials and n_jobs is for parralelization\n",
        "    if model == 'SVM':\n",
        "      study.optimize(objective_SVM, n_trials = n,n_jobs=-1) #number of trials and n_jobs is for parralelization\n",
        "    if model == \"Tree\":\n",
        "      study.optimize(objective_T, n_trials = n ,n_jobs=-1) #number of trials and n_jobs is for parralelization\n",
        "    if model == \"RF\":\n",
        "      study.optimize(objective_RF, n_trials = n,n_jobs=-1) #number of trials and n_jobs is for parralelization\n",
        "    #plot_contour(study).show()\n",
        "    best= study.best_trial\n",
        "    hyper = best.params   \n",
        "      \n",
        "  #Model training \n",
        "  if model=='KNN':\n",
        "    m = KNeighborsClassifier(**hyper)\n",
        "  if model == 'SVM':\n",
        "    m = svm.SVC(**hyper, probability = True)  \n",
        "  if model == \"Tree\":\n",
        "    m = tree.DecisionTreeClassifier(random_state=123,criterion='entropy', **hyper) \n",
        "  if model == \"RF\":\n",
        "    m = RandomForestClassifier(random_state=123,criterion='entropy', **hyper)\n",
        "  if flow == True: \n",
        "    #fit and predict with model  \n",
        "    m.fit(X_train,y_train)\n",
        "    y_pred = m.predict(X_val)\n",
        "    #calculate probabilities\n",
        "    y_prob = m.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    return y_val, y_pred, y_prob\n",
        "  if flow == False:\n",
        "    return m, hyper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUBQUz3FfT6z"
      },
      "source": [
        "#Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBRHz9oEOcRm"
      },
      "outputs": [],
      "source": [
        "#model evaluation\n",
        "def evaluation(y_test,y_pred,y_prob=None):\n",
        "  # Model Accuracy\n",
        "  print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
        "  #Precision\n",
        "  print(\"Precision:\",precision_score(y_test, y_pred))\n",
        "  #Recall\n",
        "  print(\"Recall:\",recall_score(y_test, y_pred))\n",
        "  #Confusion matrix\n",
        "  cf =confusion_matrix(y_test,y_pred)\n",
        "  plt.matshow(cf)\n",
        "  plt.title('Confusion Matrix Plot')\n",
        "  plt.colorbar()\n",
        "  plt.xlabel('Precited')\n",
        "  plt.ylabel('Actual')\n",
        "  plt.show();\n",
        "  #ROC curve and AUC score\n",
        "\n",
        "  #roc curve calculation\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "  #auc calculation\n",
        "  auc = roc_auc_score(y_test, y_prob)\n",
        "  print('AUC: %.3f' % auc)\n",
        "  plt.plot(fpr, tpr, linestyle='--', label='Roc curve')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Selection function"
      ],
      "metadata": {
        "id": "MD35kbJVNpXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.linear_model import Lasso"
      ],
      "metadata": {
        "id": "JyLQhqeeqIhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-03UHRA0fh6"
      },
      "outputs": [],
      "source": [
        "#feature selection function \n",
        "def selection(type, df):\n",
        "  X, y, X_train , X_test, y_train , y_test = split(df)  \n",
        "  # PCA\n",
        "  if type=='PCA':\n",
        "    pca = PCA(n_components=5)\n",
        "    principalComponents = pca.fit_transform(X)\n",
        "    principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['principal component 1', 'principal component 2','principal component 3','principal component 4','principal component 5'])\n",
        "    print(\"PCA Explainded variance ratio {}\".format(pca.explained_variance_ratio_))\n",
        "    principalDf['CONDITION']=y\n",
        "    return principalDf\n",
        "\n",
        "  if type == 'SelectKBest':\n",
        "    sel = SelectKBest(score_func=chi2, k=6)\n",
        "    sel.fit(X_train, y_train)\n",
        "    X_train_sel = sel.transform(X_train)\n",
        "    X_test_sel = sel.transform(X_test)\n",
        "    return X_train_sel, X_test_sel\n",
        "\n",
        "  if type == 'LASSO':\n",
        "    #---------------------------------------------------------------------------------------------------\n",
        "    # feature selection by LASSO, linear regression\n",
        "    # Hyperparameter: alpha(lambda)\n",
        "    # Note: The input X must be converted to DataFrame first as it is required for the selected features.\n",
        "    #---------------------------------------------------------------------------------------------------\n",
        "\n",
        "    #defining a standard scaler\n",
        "    scaler=StandardScaler().fit(X_train)\n",
        "    X_train=scaler.transform(X_train)\n",
        "    X_test=scaler.transform(X_test)\n",
        "\n",
        "    # convert to dataframe\n",
        "    X = pd.DataFrame(X)\n",
        "    X_train = pd.DataFrame(X_train)\n",
        "    X_test = pd.DataFrame(X_test)\n",
        "    \n",
        "    #  select the features with LASSO regularized linear regression\n",
        "    sel_lasso = SelectFromModel(      \n",
        "        Lasso(alpha=0.05, random_state=10)\n",
        "        )\n",
        "    sel_lasso.fit(X_train, y_train)\n",
        "\n",
        "    # boolean output for features with non-zero coefficients\n",
        "    sel_lasso.get_support()  \n",
        "\n",
        "    # identify the name of the removed features\n",
        "    removed_features_lasso = X_train.columns[(sel_lasso.estimator_.coef_ == 0).ravel().tolist()]\n",
        "\n",
        "    # remove the features \n",
        "    X_train_selected_lasso = sel_lasso.transform(X_train)\n",
        "    X_test_selected_lasso = sel_lasso.transform(X_test)\n",
        "\n",
        "    return X_train_selected_lasso, X_test_selected_lasso\n",
        "\n",
        "  if type == 'VAR_SEL':\n",
        "    #----------------------------------------------------------------------------------------------\n",
        "    # Feature selection by removing columns of low variance.\n",
        "    #----------------------------------------------------------------------------------------------\n",
        "\n",
        "    #defining the standard scale\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    \n",
        "\n",
        "    # set up model with threshold variance\n",
        "    sel_var = VarianceThreshold(threshold=1.2)      # How to select the threshold value properly?\n",
        "\n",
        "    # get the reuduced dataset\n",
        "    sel_var_fitted = sel_var.fit(X)\n",
        "    X_train_selected_var = sel_var_fitted.transform(X_train)\n",
        "    X_test_selected_var = sel_var_fitted.transform(X_test)\n",
        "\n",
        "    # get the selected features \n",
        "    selected_features = sel_var.get_feature_names_out()\n",
        "\n",
        "    return X_train_selected_var, X_test_selected_var, selected_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#permutation feature importance"
      ],
      "metadata": {
        "id": "GyeLdPyW0rgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from sklearn.inspection import permutation_importance"
      ],
      "metadata": {
        "id": "ihWLM9R804fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzBQSu-wdVQh"
      },
      "outputs": [],
      "source": [
        "def permutation_imp(model, dataset, perc_items): #model = SVM, KNN, Tree, RF ; dataset = df , perc_items = 0.2 \n",
        "\n",
        "  ''' \n",
        "  Return a set with a given percentage of best features selected by importance\n",
        "  '''\n",
        "\n",
        "  if perc_items < 0 or perc_items > 1:\n",
        "    print(\"Invalid number of best items: percentage needs to range between 0 and 1 \")\n",
        "  \n",
        "  elif perc_items == 0:\n",
        "    print(\"No features selected\")\n",
        "\n",
        "  elif perc_items == 1:\n",
        "    print(\"No feature selection performed. Am I joke to you?\")\n",
        "\n",
        "  else:\n",
        "    num_best_items = math.ceil(dataset.shape[1]*perc_items)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    result = permutation_importance(\n",
        "    estimator=model, \n",
        "    X=X_val,\n",
        "    y=y_val,\n",
        "    scoring='accuracy',\n",
        "    n_repeats=50,\n",
        "    random_state=0\n",
        "    )\n",
        "    \n",
        "    #indices = np.argsort(result['importances_mean'])[::-1]\n",
        "    indices = result.importances_mean.argsort()[::-1][:num_best_items]\n",
        "    best_feat_name = dataset.columns[indices]\n",
        "    best_feat_score = result['importances_mean'][indices]\n",
        "\n",
        "  return best_feat_name, best_feat_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "T8Kz8aFUKCxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test on a single dataframe\n",
        "df = df_1_DT_df_CC\n",
        "\n",
        "#splitting and scaling (with standard scaler)\n",
        "X, y, X_train , X_val, y_train , y_val = split(df) \n"
      ],
      "metadata": {
        "id": "XuWM4OQz07X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "df_pca = selection('PCA', df)\n",
        "df_pca.head()\n",
        "X, y = df_pca.iloc[:, :-2].values, df_pca.iloc[:, -1].values\n",
        "X_train , X_test, y_train , y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "y_train = y_train.astype('int')\n",
        "y_test = y_test.astype('int')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEH1oIZp6ex7",
        "outputId": "990dd8e4-d180-446e-88c1-a2e6b0620da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA Explainded variance ratio [0.25417732 0.08482543 0.07692099 0.05658873 0.04527348]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the selection function  \n",
        "#s = selection(type, df) #PCA SelectKBest LASSO VAR_SEL\n",
        "op.logging.set_verbosity(op.logging.CRITICAL)\n",
        "\n",
        "for model in [\"KNN\",\"Tree\",\"RF\",\"SVM\"]:\n",
        "    m = modelling(model,X_train, X_test, y_train, y_val, hyper = None,  tuning = True, flow = False , n = 50)[0]\n",
        "    m.fit(X_train,y_train)\n",
        "    y_pred = m.predict(X_test)\n",
        "    print('Accuracy for {}'.format(model)+'is {}'.format(accuracy_score(y_val, y_pred)))\n",
        "    print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rpMYjUT8nCT",
        "outputId": "3b01c2ff-b9c3-45dc-8566-32c3b1c3d96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for KNNis 0.7216494845360825\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Accuracy for Treeis 0.711340206185567\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n",
            "<ipython-input-11-5cf6f7958c66>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  max_depth = float(int(trial.suggest_loguniform('max_depth', 1, 32)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for RFis 0.711340206185567\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Accuracy for SVMis 0.6494845360824743\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in [\"KNN\",\"Tree\",\"RF\",\"SVM\"]:\n",
        "  y_val, y_pred, y_prob = modelling(model,X_train, X_val, y_train, y_val, hyper = None,  tuning = True, flow = True , n = 20)\n",
        "  eval = evaluation(y_val,y_pred, y_prob = y_prob)"
      ],
      "metadata": {
        "id": "ZdBeUntRKCDu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "e9cb4c76-a7d6-483c-cded-60d58e2f8f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-fe818513ecea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"KNN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Tree\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RF\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"SVM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0meval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e2132ca98a5c>\u001b[0m in \u001b[0;36mmodelling\u001b[0;34m(model, X_train, X_val, y_train, y_val, hyper, tuning, flow, n)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#fit and predict with model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m#calculate probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_precomputed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0mquery_is_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 26 features, but KNeighborsClassifier is expecting 4 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPVDcHYkIabH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLzL78tEBFdF"
      },
      "outputs": [],
      "source": [
        "#testing the permutation importance feature selection\n",
        "\n",
        "for s in [\"KNN\",\"Tree\",\"RF\",\"SVM\"]:\n",
        "  model = modelling(s,X_train, X_val, y_train, y_val, hyper = None,  tuning = True, flow = False, n = 20)[0]\n",
        "  perm = permutation_imp(model, df, perc_items=0.2)\n",
        "  print(\"Results of the permutation with model {} are {}\".format(s,perm))\n",
        "  print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 Feature Selection Method from Scikit-Learn you should know\n",
        "# Link:\n",
        "# https://towardsdatascience.com/5-feature-selection-method-from-scikit-learn-you-should-know-ed4d116e4172#:~:text=Feature%20Selection%20Sequential%20Feature%20Selection%20%28SFS%29%20New%20in,backward%20based%20on%20the%20cross-validation%20score%20an%20estimator.\n"
      ],
      "metadata": {
        "id": "A55gE3-7jNeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================================================================\n",
        "#-----------------------------------------------Pairwise-correlation-------------------------------------------------------------\n",
        "# Remove columns that are highly correlated\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# sklearn Package:\n",
        "# sklearn.metrics.pairwise_distances(X, Y=None, metric='correlation', *, n_jobs=None, force_all_finite=True, **kwds)\n",
        "#It is important to use 'correlation' metric to get the correct result, see link (2).\n",
        "# Links: \n",
        "# (1) Pairwise distance (general)\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html\n",
        "# (2) pairwise distance with metric correlation\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.correlation.html#scipy.spatial.distance.correlation\n",
        "# https://stackoverflow.com/questions/55579191/what-does-sklearns-pairwise-distances-with-metric-correlation-do\n",
        "#---------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "9SE90VUvaBlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================================================================\n",
        "#----------------------------------------------Correlation With Target-----------------------------------------------------------\n",
        "# Select the columns that are highly correlated with the target value\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# sklearn Package: \n",
        "# sklearn.cross_decomposition.CCA  (Canonical Correlation Analysis)\n",
        "# Links: \n",
        "# (1) CCA\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.CCA.html\n",
        "# (2) https://stackoverflow.com/questions/69800500/how-to-calculate-correlation-coefficients-using-sklearn-cca-module\n",
        "#--------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "pnO6ZLPEaEZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================================================================\n",
        "#---------------------------------------------Recursive Feature Elimination (RFE)------------------------------------------------\n",
        "# Use a machine learning model to eliminate features after recursive training\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# sklearn Package:\n",
        "# sklearn.feature_selection.RFE \n",
        "# Links:\n",
        "# (1) RFE\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
        "#--------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "9mhjjcH7jX6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================================================================\n",
        "#---------------------------------------------Sequential Feature Selection(SFS)--------------------------------------------------\n",
        "# Greedy algorith to find best features by either going forward or backward based on the cross-validation score an estimator\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# sklearn Package:\n",
        "# sklearn.feature_selection.SequentialFeatureSelector\n",
        "# Links:\n",
        "# (1) SFS\n",
        "# sklearn.feature_selection.SequentialFeatureSelector\n",
        "#--------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "XlwNGEtlkYmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================================================================\n",
        "#---------------------------------------------Random Projection------------------------------------------------------------------\n",
        "# Feature reduction based on the Johnson-Lindenstrauss Lemma which states that the pariwise distance of two points is preserved \n",
        "# by projecting the points onto random direction P (dim(P) = m ~ log(N)) in which N is the number of sample points of the dataset.\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# General info:\n",
        "# https://stackabuse.com/random-projection-theory-and-implementation-in-python-with-scikit-learn/\n",
        "# Links:\n",
        "# (1) Johnson-Lindenstrauss-min-dim\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.random_projection.johnson_lindenstrauss_min_dim.html\n",
        "# (2) Sparse Random Projection\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.random_projection.SparseRandomProjection.html\n",
        "# (3) Gaussian Random Projection\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.random_projection.GaussianRandomProjection.html\n",
        "# -------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "dDh8h5wToJ_M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}